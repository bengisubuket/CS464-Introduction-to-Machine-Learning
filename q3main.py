# -*- coding: utf-8 -*-
"""q3main

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lc5Mq1c-aoFmlDg45X7GNPewaMp1U3vU
"""

import pandas as pd
import numpy as np

#X_test, X_train, y_test, y_traion are Pandas DataFrame
X_test_pd = pd.read_csv('/content/X_test.csv')
X_train_pd = pd.read_csv('/content/X_train.csv')

from numpy import genfromtxt
y_train = genfromtxt('y_train.csv', delimiter=' ').astype(int)
y_test = genfromtxt('y_test.csv', delimiter=' ').astype(int)

X_labels = X_train_pd.columns.tolist()
X_labels = [word for col in X_labels for word in col.split(' ')]

X_train_values = X_train_pd.values
X_train_features = np.zeros((len(X_train_values), len(X_train_values[0][0].split()))).astype(int)
for i in range(len(X_train_values)):
  split_values = np.array(X_train_values[i][0].split())
  X_train_features[i, :len(split_values)] = split_values

X_test_values = X_test_pd.values
X_test_features = np.zeros((len(X_test_values), len(X_test_values[0][0].split()))).astype(int)
for i in range(len(X_test_values)):
  split_values = np.array(X_test_values[i][0].split())
  X_test_features[i, :len(split_values)] = split_values

"""Question 3.2: Multinomial Naive Bayes"""

import numpy as np

class MultinomialNaiveBayes:
    def __init__(self):
        self.class_probs = None
        self.feature_probs = None

    def fit(self, X_train, y_train):
        unique_classes, class_counts = np.unique(y_train, return_counts=True)
        total_samples = len(y_train)
        self.class_probs = class_counts / total_samples

        self.feature_probs = {}
        for c in unique_classes:
            X_c = X_train[y_train == c]
            feature_probs_c = (np.sum(X_c, axis=0)) / (np.sum(X_c) + X_train.shape[1])
            self.feature_probs[c] = feature_probs_c

    def predict(self, X_test):
        predictions = []
        for sample in X_test:
            class_likelihoods = []

            for c, prob_c in zip(self.feature_probs.keys(), self.class_probs):
                feature_probs_c = np.where(self.feature_probs[c] == 0, 1e-12, self.feature_probs[c])
                likelihood = np.sum(np.log(feature_probs_c) * sample)
                class_likelihoods.append(np.log(prob_c) + likelihood)

            predictions.append(list(self.feature_probs.keys())[np.argmax(class_likelihoods)])

        return np.array(predictions)

nb_classifier = MultinomialNaiveBayes()
nb_classifier.fit(X_train_features, y_train)
nb_predictions = nb_classifier.predict(X_test_features)

def confusionMatrix(labels, estimations):
    classes = np.unique(labels)
    confMatrix = np.zeros((len(classes), len(classes)))

    for i in range(len(classes)):
        for j in range(len(classes)):
           confMatrix[i, j] = np.sum((labels == classes[i]) & (estimations == classes[j]))

    return confMatrix

correct_est = np.sum(y_test == nb_predictions)

print("Accuracy: {:.3f}".format(float(correct_est/len(X_test_features))))
print("Number of correct predictions:", correct_est)
print("Number of wrong predictions:", (len(X_test_features) - correct_est))
print("Confusion Matrix: ")
print(confusionMatrix(y_test, nb_predictions))

"""Question 3.3: Multinomial Naive Bayes with Dirichlet prior"""

class MultinomialNaiveBayesWithPrior:
    def __init__(self, alpha=1):
        self.alpha = alpha
        self.class_probs = None
        self.feature_probs = None

    def fit(self, X_train, y_train):
        unique_classes, class_counts = np.unique(y_train, return_counts=True)
        total_samples = len(y_train)
        self.class_probs = class_counts / total_samples

        self.feature_probs = {}
        for c in unique_classes:
            X_c = X_train[y_train == c]
            feature_probs_c = (np.sum(X_c, axis=0) + self.alpha) / (np.sum(X_c) + self.alpha * X_train.shape[1])
            self.feature_probs[c] = feature_probs_c

    def predict(self, X_test):
        predictions = []
        for sample in X_test:
            class_likelihoods = []

            for c, prob_c in zip(self.feature_probs.keys(), self.class_probs):
                likelihood = np.sum(np.log(self.feature_probs[c]) * sample)
                class_likelihoods.append(np.log(prob_c) + likelihood)

            predictions.append(list(self.feature_probs.keys())[np.argmax(class_likelihoods)])

        return np.array(predictions)

nb_classifier_w_prior = MultinomialNaiveBayesWithPrior(alpha=1)
nb_classifier_w_prior.fit(X_train_features, y_train)
nb_w_prior_predictions = nb_classifier.predict(X_test_features)

correct_est = np.sum(y_test == nb_w_prior_predictions)

print("Accuracy: {:.3f}".format(float(correct_est/len(X_test_features))))
print("Number of correct predictions:", correct_est)
print("Number of wrong predictions:", (len(X_test_features) - correct_est))
print("Confusion Matrix: ")
print(confusionMatrix(y_test, nb_w_prior_predictions))

"""Question 3.4: Bernoulli Naive Bayes"""

class BernoulliNaiveBayes:
    def __init__(self, alpha=1):
        self.alpha = alpha
        self.class_probs = None
        self.feature_probs = None

    def fit(self, X_train, y_train):
        unique_classes, class_counts = np.unique(y_train, return_counts=True)
        total_samples = len(y_train)
        self.class_probs = class_counts / total_samples

        self.feature_probs = {}
        for c in unique_classes:
            X_c = X_train[y_train == c]
            feature_probs_c = (np.sum(X_c, axis=0) + 1) / (len(X_train) + 2)
            self.feature_probs[c] = feature_probs_c

    def predict(self, X_test):
        predictions = []
        for sample in X_test:
            sample_processed = np.where(sample != 0, 1, sample)

            class_likelihoods = []

            for c, prob_c in zip(self.feature_probs.keys(), self.class_probs):
                likelihood = np.sum(np.log(self.feature_probs[c] * sample_processed + (1 - self.feature_probs[c]) * (1 - sample_processed)))
                class_likelihoods.append(np.log(prob_c) + likelihood)

            predictions.append(list(self.feature_probs.keys())[np.argmax(class_likelihoods)])

        return np.array(predictions)

bernoulli_nb_classifier = BernoulliNaiveBayes(alpha=1)
bernoulli_nb_classifier.fit(X_train_features, y_train)
bernoulli_nb_predictions = bernoulli_nb_classifier.predict(X_test_features)

correct_est = np.sum(y_test == bernoulli_nb_predictions)

print("Accuracy: {:.3f}".format(float(correct_est/len(X_test_features))))
print("Number of correct predictions:", correct_est)
print("Number of wrong predictions:", (len(X_test_features) - correct_est))
print("Confusion Matrix: ")
print(confusionMatrix(y_test, bernoulli_nb_predictions))